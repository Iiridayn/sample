Hyperthreading:
Hyperthreading is a way of having multiple 'virtual' processors on die, executing instructions simultaniously.  Often while executing programs, there is a fair bit of unused capability, due to instructions frequently relying on results of previous instructions.  This usued capability still exists, despite reordering instructions to help improve processor usage.  Hyperthreading allows the proccessor to grab instructions from multiple proccesses simultaniously, to fill the gaps left by other proccesses.  As a result, the processor is much more likely to be able to run at full capacity.  However, running at full capacity can be risky, as it is easy to run *above* full capacity from that point, and there are a number of problems that can result.  As things stand, I will wait until time has proven the technology reliable and useful (and brought down the price).

Branch Prediction:
There are two types of branch prediction used in modern processors today; static and dynamic.  Static prediction assumes that backwards branches are taken, and forwards branches are not taken.  This is due to loops commonly being in code, and loops frequently executing multiple times.  There is also dynamic branch prediction, where the proccessor stores similar branches, and based on past history, tries to determine if it will be taken again.  Also, the target of the branch is stored in another cache, in case the prediction was wrong.  Static prediction is used only if no history exists.  The P4 has a huge branch history, as it takes a very large performance hit if it guesses wrong.  The PIII had a hit rate of about 91%, and it is safe to presume that due to the even more critical nature of branch prediction on the P4, it is even more accurate.

Execution Trace Cache:
The trace cache is an innovative L1 cache for the P4.  As you know, x86 instructions are converted into micro-ops, which are then executed by the processor.  What the P4 does, is cache the converted instructions in the trace cache.  Then, instead of re-translating the instructions, it can go straight to the trace cache and retrive them from there.  (also, for the really long instructions, hundereds of micro-ops, they are stored on a ROM, and accesed with a placer instruction.  The schedualer never notices the difference).  This permits significant speed-ups in the fetch phase.  In addition, the trace cache stores the code for the probable branch point, further increasing efficiency.

Out Of program Order:
To execute instructions out of order, the processor must first rearrange the registers used, from the 8 in the ISA to the 128 the hardware has.  It then has to schedual the tasks, so that not only do the tasks not try to use the same register, but also ensuring that the result of one computation is available for the next one to use when it needs it.  It is oblivious to which logical processor is being used.  It then sends them through the normal execution phase, at which point it has to put them all back together again.  The benifit of this is that instructions can be executed while 'waiting' for the result of a previous computation.
